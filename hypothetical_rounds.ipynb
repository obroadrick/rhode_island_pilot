{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity, and because we wanted to collect data from a large sample regardless of the audit's completion, we drew one round with a high stopping probability.\n",
    "However, on average fewer ballots need to be sampled when samples are drawn in multiple smaller rounds.\n",
    "In this notebook we explore how audits would have transpired for the sample we drew, if it had been drawn in smaller rounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from r2b2.contest import ContestType, Contest\n",
    "from r2b2.minerva2 import Minerva2\n",
    "from r2b2.minerva import Minerva\n",
    "from r2b2.eor_bravo import EOR_BRAVO\n",
    "from r2b2.so_bravo import SO_BRAVO\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's set all the same audit parameters and contest information\n",
    "contest_name = \"\\nSchool Construction and Renovation Projects\"\n",
    "tally = {'Approve' : 2391, 'Reject' : 1414}\n",
    "risk_limit = .1\n",
    "reported_winner = max(tally, key=tally.get) \n",
    "winner_votes = tally[reported_winner]\n",
    "total_relevant = sum(tally.values())\n",
    "loser_votes = total_relevant - winner_votes\n",
    "margin = (winner_votes / total_relevant) - (loser_votes / total_relevant)\n",
    "contest_reported = Contest(total_relevant, \n",
    "                            tally, \n",
    "                            num_winners=1, \n",
    "                            reported_winners=[reported_winner],\n",
    "                            contest_type=ContestType.PLURALITY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Approve</th>\n",
       "      <th>Reject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Approve  Reject\n",
       "0      0        1       0\n",
       "1      1        1       0\n",
       "2      2        1       0\n",
       "3      3        0       1\n",
       "4      4        0       1"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the sample from csv file\n",
    "df = pd.read_csv('test_sample_.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Approve': 65, 'Reject': 40, 'Approve_so': array([1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "       0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0,\n",
      "       0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0,\n",
      "       1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0,\n",
      "       1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0]), 'Reject_so': array([0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
      "       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
      "       1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1,\n",
      "       0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1,\n",
      "       0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1])}\n"
     ]
    }
   ],
   "source": [
    "# Construct the sample_dict expected by r2b2\n",
    "df_array = df.to_numpy()\n",
    "sample = {\n",
    "    'Approve': sum(df_array[:,1]),\n",
    "    'Reject': sum(df_array[:,2]),\n",
    "    'Approve_so': df_array[:,1],\n",
    "    'Reject_so': df_array[:,2],\n",
    "}\n",
    "# Useful constant\n",
    "MAXIMUM_POSSIBLE_SAMPLE = len(sample['Approve_so'])\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a function to run any hypothetical round schedule and print the results\n",
    "def hypothetical_round_schedule(sample, round_schedule):\n",
    "    # Divide the sample according to this round schedule\n",
    "    samples = []\n",
    "    for round_size in round_schedule:\n",
    "        approve_so = sample['Approve_so'][0:round_size]\n",
    "        approve = sum(approve_so)\n",
    "        reject_so = sample['Reject_so'][0:round_size]\n",
    "        reject = sum(reject_so)\n",
    "        samples.append({'Approve_so':approve_so, 'Approve':approve, 'Reject_so':reject_so, 'Reject':reject})\n",
    "    # Now create new audit objects to run this hypothetical audit with each of the BRAVOs and Minervas\n",
    "    minerva2 = ('Minerva 2.0', Minerva2(risk_limit, 1.0, contest_reported))\n",
    "    minerva = ('Minerva', Minerva(risk_limit, 1.0, contest_reported))\n",
    "    so_bravo = ('Selection-Ordered BRAVO', SO_BRAVO(risk_limit, 1.0, contest_reported))\n",
    "    eor_bravo = ('End-of-Round BRAVO', EOR_BRAVO(risk_limit, 1.0, contest_reported))\n",
    "    audits = [minerva2, minerva, so_bravo, eor_bravo]\n",
    "    # Run the hypothetical audits, printing the results\n",
    "    for audit_name, audit in audits:\n",
    "        print('{}:'.format(audit_name))\n",
    "        for i, (round_size, round_sample) in enumerate(zip(round_schedule, samples)):\n",
    "            audit.execute_round(round_size, round_sample)\n",
    "            print('Round {}: {} total, {} winner: risk {} -- stopped: {}'.format(i+1, round_size, round_sample['Approve'], round(audit.pvalue_schedule[-1], 4), audit.stopped))\n",
    "            if audit.stopped:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for getting a round schedule corresponding to a divisor\n",
    "def round_schedule(divisor):\n",
    "    marginal_round_schedule = [len(sample['Approve_so']) // divisor] * (divisor - 1)\n",
    "    marginal_round_schedule.append(len(sample['Approve_so']) - (len(sample['Approve_so']) // divisor) * (divisor - 1))\n",
    "    cumulative_round_schedule = [sum(marginal_round_schedule[0:i+1]) for i in range(len(marginal_round_schedule))]\n",
    "    return cumulative_round_schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minerva 2.0:\n",
      "Round 1: 52 total, 32 winner: risk 0.0993 -- stopped: True\n",
      "Minerva:\n",
      "Round 1: 52 total, 32 winner: risk 0.0993 -- stopped: True\n",
      "Selection-Ordered BRAVO:\n",
      "Round 1: 52 total, 32 winner: risk 0.252 -- stopped: False\n",
      "Round 2: 105 total, 65 winner: risk 0.0918 -- stopped: True\n",
      "End-of-Round BRAVO:\n",
      "Round 1: 52 total, 32 winner: risk 0.252 -- stopped: False\n",
      "Round 2: 105 total, 65 winner: risk 0.0505 -- stopped: True\n"
     ]
    }
   ],
   "source": [
    "# Let's try the function above\n",
    "hypothetical_round_schedule(sample, round_schedule(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# While Minerva 1.0 requires predetermined round sizes, Minerva 2.0 could run picking round sizes that achieve some desired stopping probability\n",
    "# Here's a similar hypothetical round schedule function but now round sizes are determined by some stopping probability\n",
    "def hypothetical_by_sprob(sample, sprob):\n",
    "    # Now create new audit objects to run this hypothetical audit with each of the BRAVOs and Minervas\n",
    "    minerva2 = ('Minerva 2.0', Minerva2(risk_limit, 1.0, contest_reported))\n",
    "    minerva = ('Minerva', Minerva(risk_limit, 1.0, contest_reported))\n",
    "    so_bravo = ('Selection-Ordered BRAVO', SO_BRAVO(risk_limit, 1.0, contest_reported))\n",
    "    eor_bravo = ('End-of-Round BRAVO', EOR_BRAVO(risk_limit, 1.0, contest_reported))\n",
    "    audits = [minerva2, minerva, so_bravo, eor_bravo]\n",
    "    # Run the hypothetical audits, printing the results\n",
    "    for audit_name, audit in audits:\n",
    "        print('{}:'.format(audit_name))\n",
    "        round_num = 0\n",
    "        while True:\n",
    "            round_num += 1\n",
    "            # Determine the next round size\n",
    "            if audit_name == 'Minerva' and round_num > 1:\n",
    "                round_size = int(round_size + round_size * 1.5)\n",
    "            else:\n",
    "                round_size = audit.next_sample_size(sprob)\n",
    "            if round_size > MAXIMUM_POSSIBLE_SAMPLE:\n",
    "                print('Next round size would be {} which exceeds the sample we drew of {}'.format(round_size, MAXIMUM_POSSIBLE_SAMPLE))\n",
    "                break\n",
    "\n",
    "            # Get the sample for this round size\n",
    "            approve_so = sample['Approve_so'][0:round_size]\n",
    "            approve = sum(approve_so)\n",
    "            reject_so = sample['Reject_so'][0:round_size]\n",
    "            reject = sum(reject_so)\n",
    "            cur_sample = {'Approve_so':approve_so, 'Approve':approve, 'Reject_so':reject_so, 'Reject':reject}\n",
    "\n",
    "            # Execute the round\n",
    "            audit.execute_round(round_size, cur_sample)\n",
    "            print('Round {}: {} total, {} winner: risk {} -- stopped: {}'.format(round_num, round_size, cur_sample['Approve'], round(audit.pvalue_schedule[-1], 4), audit.stopped))\n",
    "            if audit.stopped:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minerva 2.0:\n",
      "Round 1: 44 total, 27 winner: risk 0.1352 -- stopped: False\n",
      "Round 2: 61 total, 38 winner: risk 0.0989 -- stopped: True\n",
      "Minerva:\n",
      "Round 1: 44 total, 27 winner: risk 0.1352 -- stopped: False\n",
      "Next round size would be 110 which exceeds the sample we drew of 105\n",
      "Selection-Ordered BRAVO:\n",
      "Round 1: 52 total, 32 winner: risk 0.252 -- stopped: False\n",
      "Round 2: 68 total, 43 winner: risk 0.0918 -- stopped: True\n",
      "End-of-Round BRAVO:\n",
      "Round 1: 70 total, 44 winner: risk 0.0963 -- stopped: True\n"
     ]
    }
   ],
   "source": [
    "# Try out this new function\n",
    "hypothetical_by_sprob(sample, .5)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e774977668b7c0ae8309835a5187aa7fbf7669e7d0bb59755bc63e573643edcd"
  },
  "kernelspec": {
   "display_name": "Python 3.7.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
