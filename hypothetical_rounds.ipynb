{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity, and because we wanted to collect data from a large sample regardless of the audit's completion, we drew one round with a high stopping probability.\n",
    "However, on average fewer ballots need to be sampled when samples are drawn in multiple smaller rounds.\n",
    "In this notebook we explore how audits would have transpired for the sample we drew, if it had been drawn in smaller rounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from r2b2.contest import ContestType, Contest\n",
    "from r2b2.minerva2 import Minerva2\n",
    "from r2b2.minerva import Minerva\n",
    "from r2b2.eor_bravo import EOR_BRAVO\n",
    "from r2b2.so_bravo import SO_BRAVO\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's set all the same audit parameters and contest information\n",
    "contest_name = \"\\nSchool Construction and Renovation Projects\"\n",
    "tally = {'Approve' : 2391, 'Reject' : 1414}\n",
    "risk_limit = .1\n",
    "reported_winner = max(tally, key=tally.get) \n",
    "winner_votes = tally[reported_winner]\n",
    "total_relevant = sum(tally.values())\n",
    "loser_votes = total_relevant - winner_votes\n",
    "margin = (winner_votes / total_relevant) - (loser_votes / total_relevant)\n",
    "contest_reported = Contest(total_relevant, \n",
    "                            tally, \n",
    "                            num_winners=1, \n",
    "                            reported_winners=[reported_winner],\n",
    "                            contest_type=ContestType.PLURALITY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/obroadrick/.local/lib/python3.7/site-packages/pandas/compat/__init__.py:124: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Yes</th>\n",
       "      <th>No</th>\n",
       "      <th>Irrelevant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Yes  No  Irrelevant\n",
       "0           1    1   0           0\n",
       "1           2    1   0           0\n",
       "2           3    1   0           0\n",
       "3           4    0   1           0\n",
       "4           5    0   1           0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the sample from csv file\n",
    "import pandas as pd\n",
    "df = pd.read_csv('test_sample.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Approve': 66, 'Reject': 50, 'Approve_so': array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1,\n",
      "       1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1,\n",
      "       0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0,\n",
      "       0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
      "       0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
      "       1, 1, 1, 0, 0]), 'Reject_so': array([0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
      "       0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
      "       1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1,\n",
      "       1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
      "       1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
      "       1, 0, 0, 1, 1])}\n"
     ]
    }
   ],
   "source": [
    "# Construct the sample_dict expected by r2b2\n",
    "df_array = df.to_numpy()\n",
    "sample = {\n",
    "    'Approve': sum(df_array[:,1]),\n",
    "    'Reject': sum(df_array[:,2]),\n",
    "    'Approve_so': df_array[:,1],\n",
    "    'Reject_so': df_array[:,2],\n",
    "}\n",
    "# Useful constant\n",
    "MAXIMUM_POSSIBLE_SAMPLE = len(sample['Approve_so'])\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a function to run any hypothetical round schedule and print the results\n",
    "def hypothetical_round_schedule(sample, round_schedule):\n",
    "    # Divide the sample according to this round schedule\n",
    "    samples = []\n",
    "    for round_size in round_schedule:\n",
    "        approve_so = sample['Approve_so'][0:round_size]\n",
    "        approve = sum(approve_so)\n",
    "        reject_so = sample['Reject_so'][0:round_size]\n",
    "        reject = sum(reject_so)\n",
    "        samples.append({'Approve_so':approve_so, 'Approve':approve, 'Reject_so':reject_so, 'Reject':reject})\n",
    "    # Now create new audit objects to run this hypothetical audit with each of the BRAVOs and Minervas\n",
    "    minerva2 = ('Minerva 2.0', Minerva2(risk_limit, 1.0, contest_reported))\n",
    "    minerva = ('Minerva', Minerva(risk_limit, 1.0, contest_reported))\n",
    "    so_bravo = ('Selection-Ordered BRAVO', SO_BRAVO(risk_limit, 1.0, contest_reported))\n",
    "    eor_bravo = ('End-of-Round BRAVO', EOR_BRAVO(risk_limit, 1.0, contest_reported))\n",
    "    audits = [minerva2, minerva, so_bravo, eor_bravo]\n",
    "    # Run the hypothetical audits, printing the results\n",
    "    for audit_name, audit in audits:\n",
    "        print('{}:'.format(audit_name))\n",
    "        for i, (round_size, round_sample) in enumerate(zip(round_schedule, samples)):\n",
    "            audit.execute_round(round_size, round_sample)\n",
    "            print('Round {}: {} total, {} winner: risk {} -- stopped: {}'.format(i+1, round_size, round_sample['Approve'], round(audit.pvalue_schedule[-1], 4), audit.stopped))\n",
    "            if audit.stopped:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minerva 2.0:\n",
      "Round 1: 20 total, 12 winner: risk 0.3626 -- stopped: False\n",
      "Round 2: 40 total, 25 winner: risk 0.1749 -- stopped: False\n",
      "Round 3: 100 total, 58 winner: risk 0.0801 -- stopped: True\n",
      "Minerva:\n",
      "Round 1: 20 total, 12 winner: risk 0.3626 -- stopped: False\n",
      "Round 2: 40 total, 25 winner: risk 0.143 -- stopped: False\n",
      "Round 3: 100 total, 58 winner: risk 0.1181 -- stopped: False\n",
      "Selection-Ordered BRAVO:\n",
      "Round 1: 20 total, 12 winner: risk 0.6917 -- stopped: False\n",
      "Round 2: 40 total, 25 winner: risk 0.1957 -- stopped: False\n",
      "Round 3: 100 total, 58 winner: risk 0.0943 -- stopped: True\n",
      "End-of-Round BRAVO:\n",
      "Round 1: 20 total, 12 winner: risk 0.6917 -- stopped: False\n",
      "Round 2: 40 total, 25 winner: risk 0.283 -- stopped: False\n",
      "Round 3: 100 total, 58 winner: risk 0.4529 -- stopped: False\n"
     ]
    }
   ],
   "source": [
    "# Let's try the function above\n",
    "hypothetical_round_schedule(sample, [20, 40, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# While Minerva 1.0 requires predetermined round sizes, Minerva 2.0 could run picking round sizes that achieve some desired stopping probability\n",
    "# Here's a similar hypothetical round schedule function but now round sizes are determined by some stopping probability\n",
    "def hypothetical_by_sprob(sample, sprob):\n",
    "    # Now create new audit objects to run this hypothetical audit with each of the BRAVOs and Minervas\n",
    "    minerva2 = ('Minerva 2.0', Minerva2(risk_limit, 1.0, contest_reported))\n",
    "    minerva = ('Minerva', Minerva(risk_limit, 1.0, contest_reported))\n",
    "    so_bravo = ('Selection-Ordered BRAVO', SO_BRAVO(risk_limit, 1.0, contest_reported))\n",
    "    eor_bravo = ('End-of-Round BRAVO', EOR_BRAVO(risk_limit, 1.0, contest_reported))\n",
    "    audits = [minerva2, minerva, so_bravo, eor_bravo]\n",
    "    # Run the hypothetical audits, printing the results\n",
    "    for audit_name, audit in audits:\n",
    "        print('{}:'.format(audit_name))\n",
    "        round_num = 0\n",
    "        while True:\n",
    "            round_num += 1\n",
    "            # Determine the next round size\n",
    "            if audit_name == 'Minerva' and round_num > 1:\n",
    "                round_size = int(round_size + round_size * 1.5)\n",
    "            else:\n",
    "                round_size = audit.next_sample_size(sprob)\n",
    "            if round_size > MAXIMUM_POSSIBLE_SAMPLE:\n",
    "                print('Next round size would be {} which exceeds the sample we drew of {}'.format(round_size, MAXIMUM_POSSIBLE_SAMPLE))\n",
    "                break\n",
    "\n",
    "            # Get the sample for this round size\n",
    "            approve_so = sample['Approve_so'][0:round_size]\n",
    "            approve = sum(approve_so)\n",
    "            reject_so = sample['Reject_so'][0:round_size]\n",
    "            reject = sum(reject_so)\n",
    "            cur_sample = {'Approve_so':approve_so, 'Approve':approve, 'Reject_so':reject_so, 'Reject':reject}\n",
    "\n",
    "            # Execute the round\n",
    "            audit.execute_round(round_size, cur_sample)\n",
    "            print('Round {}: {} total, {} winner: risk {} -- stopped: {}'.format(round_num, round_size, cur_sample['Approve'], round(audit.pvalue_schedule[-1], 4), audit.stopped))\n",
    "            if audit.stopped:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minerva 2.0:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'i' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9105/3975366609.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Try out this new function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhypothetical_by_sprob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_9105/3642301943.py\u001b[0m in \u001b[0;36mhypothetical_by_sprob\u001b[0;34m(sample, sprob)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;31m# Execute the round\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0maudit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_round\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Round {}: {} total, {} winner: risk {} -- stopped: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_sample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Approve'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpvalue_schedule\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0maudit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'i' is not defined"
     ]
    }
   ],
   "source": [
    "# Try out this new function\n",
    "hypothetical_by_sprob(sample, .5)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e774977668b7c0ae8309835a5187aa7fbf7669e7d0bb59755bc63e573643edcd"
  },
  "kernelspec": {
   "display_name": "Python 3.7.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
